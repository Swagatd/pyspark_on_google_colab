{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Create DataFrame from Nested JSON File in PySpark 3.0 on Colab | Part 5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNknFFPvpvrX1dpqKCqIdES"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sKILWwIvd32H","colab_type":"text"},"source":["# **Create DataFrame from Nested JSON File in PySpark 3.0 on Colab | Part 5**"]},{"cell_type":"code","metadata":{"id":"5aoeM-IXdzRD","colab_type":"code","colab":{}},"source":["!pwd\n","!ls\n","!python --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ofMqW7VAeFAT","colab_type":"code","colab":{}},"source":["#!wget https://mirrors.estointernet.in/apache/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n","!wget https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n","!tar -xvzf spark-3.0.0-bin-hadoop2.7.tgz\n","!pip install findspark\n","\n","import os\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\"\n","import findspark\n","findspark.init()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPyOO2j9eNtt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599909201926,"user_tz":-330,"elapsed":1513,"user":{"displayName":"DataMaking","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8Ck4eyinapgtobtrErZWzNt_3DfJL867BQ7JA-Q=s64","userId":"16773646856361708024"}},"outputId":"6cfec856-3e00-479d-b2c2-237a058fb80f"},"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName(\"Create DataFrame from Nested JSON File in PySpark 3.0\").getOrCreate()\n","print(spark.sparkContext.appName)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Create DataFrame from Nested JSON File in PySpark 3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vEBTnZyjeWwn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"status":"ok","timestamp":1599909232694,"user_tz":-330,"elapsed":1353,"user":{"displayName":"DataMaking","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8Ck4eyinapgtobtrErZWzNt_3DfJL867BQ7JA-Q=s64","userId":"16773646856361708024"}},"outputId":"22911089-d3e3-4263-e567-bcfd58577360"},"source":["nested_json_file_path = \"/content/data/json/sample_nested_json_file.json\"\n","\n","df = spark.read.json(path=nested_json_file_path, multiLine=True)\n","\n","df.show(10, False)\n","\n","df.printSchema()\n","\n","df.select(['CHECK.Check1', 'CHECK.Check2', 'COL', 'DATA', 'IFAM', 'KTM']).show(100, False)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["+--------+---+--------------------------------------------------------+----+-------------+\n","|CHECK   |COL|DATA                                                    |IFAM|KTM          |\n","+--------+---+--------------------------------------------------------+----+-------------+\n","|[1, TWO]|21 |[[[[k1, v1], [k2, v2]], 31], [[[k3, v3], [k4, v4]], 33]]|EQR |1548176931466|\n","+--------+---+--------------------------------------------------------+----+-------------+\n","\n","root\n"," |-- CHECK: struct (nullable = true)\n"," |    |-- Check1: long (nullable = true)\n"," |    |-- Check2: string (nullable = true)\n"," |-- COL: long (nullable = true)\n"," |-- DATA: array (nullable = true)\n"," |    |-- element: struct (containsNull = true)\n"," |    |    |-- Crate: array (nullable = true)\n"," |    |    |    |-- element: struct (containsNull = true)\n"," |    |    |    |    |-- key: string (nullable = true)\n"," |    |    |    |    |-- value: string (nullable = true)\n"," |    |    |-- MLrate: string (nullable = true)\n"," |-- IFAM: string (nullable = true)\n"," |-- KTM: long (nullable = true)\n","\n","+------+------+---+--------------------------------------------------------+----+-------------+\n","|Check1|Check2|COL|DATA                                                    |IFAM|KTM          |\n","+------+------+---+--------------------------------------------------------+----+-------------+\n","|1     |TWO   |21 |[[[[k1, v1], [k2, v2]], 31], [[[k3, v3], [k4, v4]], 33]]|EQR |1548176931466|\n","+------+------+---+--------------------------------------------------------+----+-------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6VJoCqUbuotD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599909767874,"user_tz":-330,"elapsed":1815,"user":{"displayName":"DataMaking","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8Ck4eyinapgtobtrErZWzNt_3DfJL867BQ7JA-Q=s64","userId":"16773646856361708024"}},"outputId":"77c96725-3b77-4a7e-ed97-1bc7e62a7ea9"},"source":["from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","\n","def read_nested_json(df):\n","    column_list = []\n","\n","    for column_name in df.schema.names:\n","        print(\"Outside isinstance loop: \" + column_name)\n","        # Checking column type is ArrayType\n","        if isinstance(df.schema[column_name].dataType, ArrayType):\n","            print(\"Inside isinstance loop of ArrayType: \" + column_name)\n","            df = df.withColumn(column_name, explode(column_name).alias(column_name))\n","            column_list.append(column_name)\n","\n","        elif isinstance(df.schema[column_name].dataType, StructType):\n","            print(\"Inside isinstance loop of StructType: \" + column_name)\n","            for field in df.schema[column_name].dataType.fields:\n","                column_list.append(col(column_name + \".\" + field.name).alias(column_name + \"_\" + field.name))\n","        else:\n","            column_list.append(column_name)\n","\n","    # Selecting columns using column_list from dataframe: df\n","    df = df.select(column_list)\n","    return df\n","\n","read_nested_json_flag = True\n","\n","while read_nested_json_flag:\n","  print(\"Reading Nested JSON File ... \")\n","  df = read_nested_json(df)\n","  df.show(100, False)\n","  read_nested_json_flag = False\n","\n","  for column_name in df.schema.names:\n","    if isinstance(df.schema[column_name].dataType, ArrayType):\n","      read_nested_json_flag = True\n","    elif isinstance(df.schema[column_name].dataType, StructType):\n","      read_nested_json_flag = True\n","\n","df.show(100, False)\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Reading Nested JSON File ... \n","Outside isinstance loop: CHECK\n","Inside isinstance loop of StructType: CHECK\n","Outside isinstance loop: COL\n","Outside isinstance loop: DATA\n","Inside isinstance loop of ArrayType: DATA\n","Outside isinstance loop: IFAM\n","Outside isinstance loop: KTM\n","+------------+------------+---+--------------------------+----+-------------+\n","|CHECK_Check1|CHECK_Check2|COL|DATA                      |IFAM|KTM          |\n","+------------+------------+---+--------------------------+----+-------------+\n","|1           |TWO         |21 |[[[k1, v1], [k2, v2]], 31]|EQR |1548176931466|\n","|1           |TWO         |21 |[[[k3, v3], [k4, v4]], 33]|EQR |1548176931466|\n","+------------+------------+---+--------------------------+----+-------------+\n","\n","Reading Nested JSON File ... \n","Outside isinstance loop: CHECK_Check1\n","Outside isinstance loop: CHECK_Check2\n","Outside isinstance loop: COL\n","Outside isinstance loop: DATA\n","Inside isinstance loop of StructType: DATA\n","Outside isinstance loop: IFAM\n","Outside isinstance loop: KTM\n","+------------+------------+---+--------------------+-----------+----+-------------+\n","|CHECK_Check1|CHECK_Check2|COL|DATA_Crate          |DATA_MLrate|IFAM|KTM          |\n","+------------+------------+---+--------------------+-----------+----+-------------+\n","|1           |TWO         |21 |[[k1, v1], [k2, v2]]|31         |EQR |1548176931466|\n","|1           |TWO         |21 |[[k3, v3], [k4, v4]]|33         |EQR |1548176931466|\n","+------------+------------+---+--------------------+-----------+----+-------------+\n","\n","Reading Nested JSON File ... \n","Outside isinstance loop: CHECK_Check1\n","Outside isinstance loop: CHECK_Check2\n","Outside isinstance loop: COL\n","Outside isinstance loop: DATA_Crate\n","Inside isinstance loop of ArrayType: DATA_Crate\n","Outside isinstance loop: DATA_MLrate\n","Outside isinstance loop: IFAM\n","Outside isinstance loop: KTM\n","+------------+------------+---+----------+-----------+----+-------------+\n","|CHECK_Check1|CHECK_Check2|COL|DATA_Crate|DATA_MLrate|IFAM|KTM          |\n","+------------+------------+---+----------+-----------+----+-------------+\n","|1           |TWO         |21 |[k1, v1]  |31         |EQR |1548176931466|\n","|1           |TWO         |21 |[k2, v2]  |31         |EQR |1548176931466|\n","|1           |TWO         |21 |[k3, v3]  |33         |EQR |1548176931466|\n","|1           |TWO         |21 |[k4, v4]  |33         |EQR |1548176931466|\n","+------------+------------+---+----------+-----------+----+-------------+\n","\n","Reading Nested JSON File ... \n","Outside isinstance loop: CHECK_Check1\n","Outside isinstance loop: CHECK_Check2\n","Outside isinstance loop: COL\n","Outside isinstance loop: DATA_Crate\n","Inside isinstance loop of StructType: DATA_Crate\n","Outside isinstance loop: DATA_MLrate\n","Outside isinstance loop: IFAM\n","Outside isinstance loop: KTM\n","+------------+------------+---+--------------+----------------+-----------+----+-------------+\n","|CHECK_Check1|CHECK_Check2|COL|DATA_Crate_key|DATA_Crate_value|DATA_MLrate|IFAM|KTM          |\n","+------------+------------+---+--------------+----------------+-----------+----+-------------+\n","|1           |TWO         |21 |k1            |v1              |31         |EQR |1548176931466|\n","|1           |TWO         |21 |k2            |v2              |31         |EQR |1548176931466|\n","|1           |TWO         |21 |k3            |v3              |33         |EQR |1548176931466|\n","|1           |TWO         |21 |k4            |v4              |33         |EQR |1548176931466|\n","+------------+------------+---+--------------+----------------+-----------+----+-------------+\n","\n","+------------+------------+---+--------------+----------------+-----------+----+-------------+\n","|CHECK_Check1|CHECK_Check2|COL|DATA_Crate_key|DATA_Crate_value|DATA_MLrate|IFAM|KTM          |\n","+------------+------------+---+--------------+----------------+-----------+----+-------------+\n","|1           |TWO         |21 |k1            |v1              |31         |EQR |1548176931466|\n","|1           |TWO         |21 |k2            |v2              |31         |EQR |1548176931466|\n","|1           |TWO         |21 |k3            |v3              |33         |EQR |1548176931466|\n","|1           |TWO         |21 |k4            |v4              |33         |EQR |1548176931466|\n","+------------+------------+---+--------------+----------------+-----------+----+-------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nQa3KRH681-_","colab_type":"code","colab":{}},"source":["spark.stop()"],"execution_count":null,"outputs":[]}]}